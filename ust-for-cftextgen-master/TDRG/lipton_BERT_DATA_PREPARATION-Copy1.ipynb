{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n",
    "#from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "\n",
    "from bertviz.bertviz import attention, visualization\n",
    "from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#bert_classifier_model_dir = \"./bert_classifier/\" ## Path of BERT classifier model path\n",
    "#bert_classifier_model_dir = \"./data/yelp/bert_classifier_2epochs/\"\n",
    "\n",
    "#bert_classifier_model_dir = \"./data/lipton/sentiment/orig/bert_classifier_10epochs8b_490seqlen/\"       #Apr 24\n",
    "#eval_accuracy = 0.9102040816326531  and  eval_loss = 0.35673839559838655  \n",
    "\n",
    "#bert_classifier_model_dir = \"./data/lipton/sentiment/orig/bert_classifier_100epochs16b/\"    #apr27\n",
    "#eval_accuracy = 0.9306122448979591   and eval_loss = 0.6695167317746147\n",
    "\n",
    "bert_classifier_model_dir = \"./data/lipton/sentiment/orig/bert_classifier_100epochs8b_490seqlen/\"  #Apr 24\n",
    "#eval_accuracy = 0.8979591836734694   and eval_loss = 0.9967757850885384           # Try with this one <--\n",
    "\n",
    "# QUESTION: Whats the difference between loss and acc?  in run_classifier.py\n",
    "\n",
    "#def accuracy(out, labels):\n",
    "#    outputs = np.argmax(out, axis=1)\n",
    "#    return np.sum(outputs == labels)\n",
    "\n",
    "# eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "# eval_sampler = SequentialSampler(eval_data)Run prediction for full data\n",
    "# eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "# model.eval()\n",
    "\n",
    "# eval_loss, eval_accuracy, nb_eval_steps, nb_eval_examples = 0, 0, 0, 0\n",
    "\n",
    "# for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "#    ...\n",
    "#    tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "#    ...\n",
    "#    tmp_eval_accuracy = accuracy(logits, label_ids)   #\n",
    "#    ...\n",
    "#    eval_loss += tmp_eval_loss.mean().item()\n",
    "#    eval_accuracy += tmp_eval_accuracy\n",
    "#    ...\n",
    "#    nb_eval_examples += input_ids.size(0)\n",
    "#    nb_eval_steps += 1\n",
    "# ..\n",
    "# eval_loss = eval_loss / nb_eval_steps                 <--- loss is sum of batch mean losses / nb_steps\n",
    "# eval_accuracy = eval_accuracy / nb_eval_examples      <--- acc  is sum of each accuracy / nmb_examples  ( a little more fine grained)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851/851 [00:00<00:00, 27865.32it/s]\n",
      "100%|██████████| 856/856 [00:00<00:00, 30922.55it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 24947.84it/s]\n",
      "100%|██████████| 123/123 [00:00<00:00, 30449.12it/s]\n",
      "100%|██████████| 243/243 [00:00<00:00, 32004.52it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 33994.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#before doing the following I need to create sentiment_train_0 , sentiment_train_1 , etc versions of our training data\n",
    "def create_classification_file(input_df, output_file_path):\n",
    "    with open(output_file_path, \"w\") as out_fp:\n",
    "        writer = csv.writer(out_fp, delimiter=\"\\t\")\n",
    "        for i in tqdm(range(input_df.shape[0])):\n",
    "            line = input_df.Text.values[i]\n",
    "            writer.writerow([line.strip()])\n",
    "            \n",
    "import pandas as pd\n",
    "origd = \"data/lipton/sentiment/orig/bert_classifier_training/\"\n",
    "train_df = pd.read_table(origd+\"train.csv\",sep=\"\\t\",header=None,names=[\"Text\",\"sentiment\"])\n",
    "dev_df = pd.read_table(origd+\"dev.csv\",sep=\"\\t\",header=None,names=[\"Text\",\"sentiment\"])\n",
    "test_df = pd.read_table(origd+\"test.csv\",sep=\"\\t\",header=None,names=[\"Text\",\"sentiment\"])\n",
    "\n",
    "train_neg = train_df[train_df.sentiment == 0][[\"Text\"]]\n",
    "train_pos = train_df[train_df.sentiment == 1][[\"Text\"]]\n",
    "dev_neg = dev_df[dev_df.sentiment == 0][[\"Text\"]]\n",
    "dev_pos = dev_df[dev_df.sentiment == 1][[\"Text\"]]\n",
    "test_neg = test_df[test_df.sentiment == 0][[\"Text\"]]\n",
    "test_pos = test_df[test_df.sentiment == 1][[\"Text\"]]\n",
    "\n",
    "create_classification_file(train_neg, origd+\"sentiment_train_0.txt\" )\n",
    "create_classification_file(train_pos, origd+\"sentiment_train_1.txt\" )\n",
    "create_classification_file(dev_neg, origd+\"sentiment_dev_0.txt\" )\n",
    "create_classification_file(dev_pos, origd+\"sentiment_dev_1.txt\" )\n",
    "create_classification_file(test_neg, origd+\"sentiment_test_0.txt\" )\n",
    "create_classification_file(test_pos, origd+\"sentiment_test_1.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 856/856 [00:00<00:00, 26320.48it/s]\n",
      "100%|██████████| 851/851 [00:00<00:00, 30968.64it/s]\n",
      "100%|██████████| 123/123 [00:00<00:00, 28007.57it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 27377.08it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 31933.02it/s]\n",
      "100%|██████████| 243/243 [00:00<00:00, 32431.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#also need to handle reference data!! \n",
    "refd = \"./data/lipton/sentiment/new/\"\n",
    "train_df = pd.read_table(refd+\"train.tsv\",sep=\"\\t\")\n",
    "dev_df = pd.read_table(refd+\"dev.tsv\",sep=\"\\t\")\n",
    "test_df = pd.read_table(refd+\"test.tsv\",sep=\"\\t\")\n",
    "\n",
    "rtrain_neg = train_df[train_df.Sentiment == \"Negative\"][[\"Text\"]]\n",
    "rtrain_pos = train_df[train_df.Sentiment == \"Positive\"][[\"Text\"]]\n",
    "rdev_neg = dev_df[dev_df.Sentiment == \"Negative\"][[\"Text\"]]\n",
    "rdev_pos = dev_df[dev_df.Sentiment == \"Positive\"][[\"Text\"]]\n",
    "rtest_neg = test_df[test_df.Sentiment == \"Negative\"][[\"Text\"]]\n",
    "rtest_pos = test_df[test_df.Sentiment == \"Positive\"][[\"Text\"]]\n",
    "\n",
    "create_classification_file(rtrain_neg, refd+\"ref_sentiment_train_0.txt\" )\n",
    "create_classification_file(rtrain_pos, refd+\"ref_sentiment_train_1.txt\" )\n",
    "create_classification_file(rdev_neg, refd+\"ref_sentiment_dev_0.txt\" )\n",
    "create_classification_file(rdev_pos, refd+\"ref_sentiment_dev_1.txt\" )\n",
    "create_classification_file(rtest_neg, refd+\"ref_sentiment_test_0.txt\" )\n",
    "create_classification_file(rtest_pos, refd+\"ref_sentiment_test_1.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat ref_sentiment_train_0.txt ref_sentiment_dev_0.txt ref_sentiment_test_0.txt > reference_0.txt\n",
    "# cat ref_sentiment_train_1.txt ref_sentiment_dev_1.txt ref_sentiment_test_1.txt > reference_1.txt\n",
    "\n",
    "# however looking at YELP.. the reference is just against the test set .. so we might just want to do it against\n",
    "# ref_sentiment_test_0.txt  AND ref_sentiment_test_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENTS OF BERT_CLASSIFIER_TRAINING\n",
    "#diego@microdeep:~/spr20_cf_gen/TDRG/data/lipton/sentiment/orig/bert_classifier_training$ ls\n",
    "#dev.csv                                   reference_1.txt      sentiment_test_0.txt   sentiment_train_1.txt  tfidf_train1.ann\n",
    "#processed_files_with_bert_with_best_head  sentiment_dev_0.txt  sentiment_test_1.txt   test.csv               train.csv\n",
    "#reference_0.txt                           sentiment_dev_1.txt  sentiment_train_0.txt  tfidf_train0.ann\n",
    "\n",
    "# IMPORTANT:\n",
    "# FOLDER: bert_classifier_training//processed_files_with_bert_with_best_head/   \n",
    "#  --> BASED ON (9,5):  bert_classifier_10epochs8b_490seqlen/\n",
    "\n",
    "# NOW select other BERT MODEL TO use and store info/results in its folder (ie, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "#data_dir = \"/home/ubuntu/bhargav/data/\"\n",
    "#data_dir = \"/home/diego/spr20_cf_gen/TDRG/data/\"\n",
    "#dataset = \"yelp\" # amazon / yelp / imagecaption\n",
    "\n",
    "data_dir = \"data/lipton/sentiment/orig/\"\n",
    "dataset = \"bert_classifier_training/\"\n",
    "refd = \"./data/lipton/sentiment/new/\"\n",
    "\n",
    "train_0 = os.path.join(data_dir ,\"{}/sentiment_train_0.txt\".format(dataset))\n",
    "train_1 = os.path.join(data_dir,\"./{}/sentiment_train_1.txt\".format(dataset))\n",
    "test_0 = os.path.join(data_dir,\"./{}/sentiment_test_0.txt\".format(dataset))\n",
    "test_1 = os.path.join(data_dir,\"./{}/sentiment_test_1.txt\".format(dataset))\n",
    "dev_0 = os.path.join(data_dir,\"./{}/sentiment_dev_0.txt\".format(dataset))\n",
    "dev_1 = os.path.join(data_dir,\"./{}/sentiment_dev_1.txt\".format(dataset))\n",
    "reference_0 = os.path.join(refd,\"ref_sentiment_test_0.txt\")\n",
    "reference_1 = os.path.join(refd,\"ref_sentiment_test_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "#data_dir = \"/home/ubuntu/bhargav/data/\"\n",
    "#data_dir = \"/home/diego/spr20_cf_gen/TDRG/data/\"\n",
    "#dataset = \"yelp\" # amazon / yelp / imagecaption\n",
    "\n",
    "train_0_out = os.path.join(data_dir ,\"./{}/processed_files_with_bert_with_best_head/sentiment_train_0.txt\".format(dataset))\n",
    "train_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment_train_1.txt\".format(dataset))\n",
    "test_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment_test_0.txt\".format(dataset))\n",
    "test_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment_test_1.txt\".format(dataset))\n",
    "dev_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment_dev_0.txt\".format(dataset))\n",
    "dev_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment_dev_1.txt\".format(dataset))\n",
    "reference_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/reference_0.txt\".format(dataset))\n",
    "reference_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/reference_1.txt\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Model for performing Classification\n",
    "model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model_cls.to(device)\n",
    "model_cls.eval()\n",
    "\"\"\"\n",
    "\n",
    "## Model to get the attention weights of all the heads\n",
    "#model = BertModel.from_pretrained(bert_classifier_model_dir)         #from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "\n",
    "#instead: maybe I should use not the bertviz one?  \n",
    "model = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n",
    "# NO  this way runs out of memory when doing attribution\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_seq_len=70 # Maximum sequence length \n",
    "max_seq_len = 490\n",
    "sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=['is','are','was','were','has','have','had','a','an','the','this','that','these','those','there','how','i','we',\n",
    "             'he','she','it','they','them','their','his','him','her','us','our', 'and','in','my','your','you', 'will', 'shall']\n",
    "common_words_tokens = tokenizer.convert_tokens_to_ids(common_words)\n",
    "not_to_remove_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\",\"[SEP]\", \".\", \"?\", \"!\"])\n",
    "not_to_remove_ids += common_words_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path) as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_file(original_sentences,processed_sentences, output_file, sentiment=\"<POS>\"):\n",
    "    with open(output_file,\"w\") as fp:\n",
    "        for sen1,sen2 in zip(original_sentences,processed_sentences):\n",
    "            if sen1 != None and sen2 != None:\n",
    "                str1 = sentiment + \" <CON_START> \" + sen2 + \" <START> \" + sen1 + \" <END>\\n\"\n",
    "                fp.write(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n",
    "    with open(output_file,\"w\") as fp:\n",
    "        for sen in tqdm(processed_sentences):\n",
    "            if sen != None:\n",
    "                str1 = sentiment + \" <CON_START> \" + sen + \" <START>\\n\"\n",
    "                fp.write(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_files(inp_files, out_files):\n",
    "    with open(out_files,\"w\") as fp:\n",
    "        for file in inp_files:\n",
    "            with open(file) as f:\n",
    "                for line in f:\n",
    "                    fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attn_examples(input_sentences, layer, head, bs=128):\n",
    "    \"\"\"\n",
    "    Returns Attention weights for selected Layer and Head along with ids and tokens\n",
    "    of the input_sentence\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    ids_to_decode = [None for k in range(len(input_sentences))]\n",
    "    tokens_to_decode = [None for k in range(len(input_sentences))]\n",
    "    segment_ids = []\n",
    "    input_masks = []\n",
    "    attention_weights = [None for z in input_sentences]\n",
    "    ## BERT pre-processing\n",
    "    for j,sen in enumerate(tqdm(input_sentences)):\n",
    "        \n",
    "        text_tokens = tokenizer.tokenize(sen)\n",
    "        if len(text_tokens) >= max_seq_len-2:\n",
    "            text_tokens = text_tokens[:max_seq_len-4]\n",
    "        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n",
    "        tokens_to_decode[j] = tokens\n",
    "        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        ids_to_decode[j] = temp_ids\n",
    "        input_mask = [1] * len(temp_ids)\n",
    "        segment_id = [0] * len(temp_ids)\n",
    "        padding = [0] * (max_seq_len - len(temp_ids))\n",
    "        \n",
    "        \n",
    "        temp_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_id += padding\n",
    "        \n",
    "        ids.append(temp_ids)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "    \n",
    "    # Convert Ids to Torch Tensors\n",
    "    ids = torch.tensor(ids) \n",
    "    segment_ids = torch.tensor(segment_ids)\n",
    "    input_masks = torch.tensor(input_masks)\n",
    "    \n",
    "    steps = len(ids) // bs\n",
    "    \n",
    "    for i in trange(steps+1):\n",
    "        if i == steps:\n",
    "            temp_ids = ids[i * bs : len(ids)]\n",
    "            temp_segment_ids = segment_ids[i * bs: len(ids)]\n",
    "            temp_input_masks = input_masks[i * bs: len(ids)]\n",
    "        else:\n",
    "            temp_ids = ids[i * bs : i * bs + bs]\n",
    "            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n",
    "            temp_input_masks = input_masks[i * bs: i * bs + bs]\n",
    "        \n",
    "        temp_ids = temp_ids.to(device)\n",
    "        temp_segment_ids = temp_segment_ids.to(device)\n",
    "        temp_input_masks = temp_input_masks.to(device)\n",
    "        with torch.no_grad():\n",
    "             _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n",
    "        # Concate Attention weights\n",
    "        for j in range(len(attn[layer]['attn_probs'])):\n",
    "            attention_weights[i * bs + j] = (attn[layer]['attn_probs'][j][head][0]).to('cpu')\n",
    "    \n",
    "    return attention_weights, ids_to_decode, tokens_to_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(aw, ids_to_decode, tokens_to_decode):\n",
    "    out_sen = [None for i in range(len(aw))]\n",
    "    for i in trange(len(aw)):        \n",
    "        topv, topi = aw[i].topk(ids_to_decode[i].index(0))\n",
    "        topi = topi.tolist()\n",
    "        topv = topv.tolist()\n",
    "\n",
    "        #print(\"Original Top Indexes = {}\".format(topi))\n",
    "        topi = [topi[j] for j in range(len(topi)) if ids_to_decode[i][topi[j]] not in not_to_remove_ids] # remove noun and common words\n",
    "        #print(\"After removing Nouns = {}\".format(topi))\n",
    "        \n",
    "        topi = [topi[j] for j in range(len(topi)) if \"##\" not in tokens_to_decode[i][topi[j]]] # Remove half words\n",
    "        #print(\"After removing Half-words = {}\".format(topi))\n",
    "\n",
    "        # DIEGO:   WHAT IS THIS DOING ? \n",
    "        if (len(topi) < 4 and len(topi) > 0):\n",
    "            topi = [topi[0]]\n",
    "        elif(len(topi) < 8):\n",
    "            topi = topi[:2]\n",
    "        else:\n",
    "            topi = topi[:3]\n",
    "\n",
    "        #print(\"Final Topi = {}\".format(topi))\n",
    "        final_indexes = []\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        #print(ids_to_decode[i], tokens_to_decode[i])\n",
    "        while ids_to_decode[i][count] != 0:\n",
    "            if count in topi:\n",
    "                while ids_to_decode[i][count + count1 + 1] != 0:\n",
    "                    if \"##\" in tokens_to_decode[i][count + count1 + 1]:\n",
    "                        count1 += 1\n",
    "                    else:\n",
    "                        break\n",
    "                count += count1\n",
    "                count1 = 0\n",
    "            else:\n",
    "                final_indexes.append(ids_to_decode[i][count])\n",
    "            count += 1\n",
    "\n",
    "        #print(final_indexes)\n",
    "        temp_out_sen = tokenizer.convert_ids_to_tokens(final_indexes)\n",
    "        temp_out_sen = \" \".join(temp_out_sen).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\")\n",
    "        #print(temp_out_sen, \"\\n\\n\")\n",
    "        out_sen[i] = temp_out_sen.strip()\n",
    "    \n",
    "    return out_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0_data = read_file(train_0)\n",
    "train_1_data = read_file(train_1)\n",
    "dev_0_data = read_file(dev_0)\n",
    "dev_1_data = read_file(dev_1)\n",
    "test_0_data = read_file(test_0)\n",
    "test_1_data = read_file(test_1)\n",
    "ref_0_data = read_file(reference_0)\n",
    "ref_1_data = read_file(reference_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.csv\t\t\t\t\t  sentiment_test_0.txt\t test.csv\n",
      "processed_files_with_bert_with_best_head  sentiment_test_1.txt\t train.csv\n",
      "sentiment_dev_0.txt\t\t\t  sentiment_train_0.txt\n",
      "sentiment_dev_1.txt\t\t\t  sentiment_train_1.txt\n"
     ]
    }
   ],
   "source": [
    "#generate files but before hand create folder data/yelp/processed_files_with_bert_with_best_head/\n",
    "!cd data/lipton/sentiment/orig/bert_classifier_training/; mkdir processed_files_with_bert_with_best_head; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851/851 [00:02<00:00, 392.14it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.31it/s]\n",
      "100%|██████████| 851/851 [00:00<00:00, 3949.22it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_0_data, layer=9, head=5, bs=16)\n",
    "train_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(train_0_data, train_0_out_sen, train_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 856/856 [00:02<00:00, 381.57it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.26it/s]\n",
      "100%|██████████| 856/856 [00:00<00:00, 3908.56it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_1_data, layer=9, head=5, bs=16)\n",
    "train_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(train_1_data, train_1_out_sen, train_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 377.07it/s]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.36it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 3514.84it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_0_data, layer=9, head=5, bs=16)\n",
    "dev_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(dev_0_data, dev_0_out_sen, dev_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:00<00:00, 329.91it/s]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.34it/s]\n",
      "100%|██████████| 123/123 [00:00<00:00, 3942.59it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_1_data, layer=9, head=5, bs=16)\n",
    "dev_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(dev_1_data, dev_1_out_sen, dev_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 404.26it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.35it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 3975.24it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_1_data, layer=9, head=5, bs=16)\n",
    "test_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(test_1_data, test_1_out_sen, test_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 399.37it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.38it/s]\n",
      "100%|██████████| 243/243 [00:00<00:00, 3778.36it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_0_data, layer=9, head=5, bs=16)\n",
    "test_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(test_0_data, test_0_out_sen, test_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAD TO DO REF work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 347.62it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.44it/s]\n",
      "100%|██████████| 243/243 [00:00<00:00, 3980.57it/s]\n",
      "100%|██████████| 243/243 [00:00<00:00, 277488.67it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_1_data, layer=9, head=5, bs=16)\n",
    "ref_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "#create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")\n",
    "#--> TypeError: create_ref_output_file() got multiple values for argument 'sentiment'\n",
    "\n",
    "#doesn't need original ref_1_data \n",
    "# def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n",
    "create_ref_output_file(ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 346.86it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.42it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 3910.84it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 278785.81it/s]\n"
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_0_data, layer=9, head=5, bs=16)\n",
    "ref_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "#create_ref_output_file(ref_0_data, ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")\n",
    "create_ref_output_file(ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE _0  and _1 files WHEN YOU GET BACK\n",
    "\n",
    "# diego@microdeep:~/spr20_cf_gen/TDRG/data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head$ cat sentiment_train_0.txt sentiment_train_1.txt > sentiment_train.txt\n",
    "# diego@microdeep:~/spr20_cf_gen/TDRG/data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head$ cat sentiment_dev_0.txt sentiment_dev_1.txt > sentiment_dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE TO Head_selection bottom when done\n",
    "# integradted gradients / expected gradients / integrated hessians\n",
    "\n",
    "# IG using captum\n",
    "# pip install captum\n",
    "# https://captum.ai/tutorials/IMDB_TorchText_Interpret  aND  https://captum.ai/docs/extension/integrated_gradients\n",
    "#!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['long', ',', 'boring', ',', 'b', '##las', '##ph', '##em', '##ous', '.', 'never', 'have', 'i', 'been', 'so', 'glad', 'to', 'see', 'ending', 'credits', 'roll', '.']\n",
      "\n",
      "Tokens id: [2146, 1010, 11771, 1010, 1038, 8523, 8458, 6633, 3560, 1012, 2196, 2031, 1045, 2042, 2061, 5580, 2000, 2156, 4566, 6495, 4897, 1012]\n",
      "\n",
      "Tokens PyTorch: tensor([[ 2146,  1010, 11771,  1010,  1038,  8523,  8458,  6633,  3560,  1012,\n",
      "          2196,  2031,  1045,  2042,  2061,  5580,  2000,  2156,  4566,  6495,\n",
      "          4897,  1012]])\n"
     ]
    }
   ],
   "source": [
    "# TAKE 1 :   NOPE\n",
    "#https://github.com/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb\n",
    "\n",
    "tokens = tokenizer.tokenize(train_0_data[0])\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "#tokens_ids = tokenizer.build_inputs_with_special_tokens(tokens_ids)  # Add the required special tokens\n",
    "tokens_pt = torch.tensor([tokens_ids])\n",
    "print(\"Tokens: {}\".format(tokens))\n",
    "print(\"\\nTokens id: {}\".format(tokens_ids))\n",
    "print(\"\\nTokens PyTorch: {}\".format(tokens_pt))\n",
    "#outputs, pooled = model(tokens_pt)  ## Now we're ready to go through BERT with out input  # <--- error\n",
    "#print(\"Token wise output: {}, Pooled output: {}\".format(outputs.shape, pooled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE 2 ( based on above method for preping example.. not sure output is right though)\n",
    "def prep_example(input_sentence, in_label=0):\n",
    "    \"\"\"\n",
    "    Returns inputs nessary for model to process a single input_sentence and its label ( 0 / 1 )\n",
    "    \"\"\"\n",
    "    debug = False\n",
    "    bs = 1\n",
    "    ids = []\n",
    "    ids_to_decode = [None]\n",
    "    tokens_to_decode = [None]\n",
    "    segment_ids = []\n",
    "    input_masks = []\n",
    "    attention_weights = [None]\n",
    "    sen = input_sentence\n",
    "    j = 0\n",
    "    max_seq_len = 490\n",
    "    text_tokens = tokenizer.tokenize(sen)\n",
    "    if len(text_tokens) >= max_seq_len-2:\n",
    "        text_tokens = text_tokens[:max_seq_len-4]\n",
    "        \n",
    "    tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n",
    "    tokens_to_decode[j] = tokens\n",
    "    temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    ids_to_decode[j] = temp_ids\n",
    "    input_mask = [1] * len(temp_ids)\n",
    "    segment_id = [0] * len(temp_ids)\n",
    "    padding = [0] * (max_seq_len - len(temp_ids))\n",
    "\n",
    "    temp_ids += padding\n",
    "    input_mask += padding\n",
    "    segment_id += padding\n",
    "\n",
    "    ids.append(temp_ids)\n",
    "    input_masks.append(input_mask)\n",
    "    segment_ids.append(segment_id)\n",
    "    \n",
    " \n",
    "    # Convert Ids to Torch Tensors\n",
    "    ids = torch.tensor(ids) \n",
    "    segment_ids = torch.tensor(segment_ids)\n",
    "    input_masks = torch.tensor(input_masks)\n",
    "    input_label = torch.tensor([in_label])\n",
    "    \n",
    "    steps = len(ids) // bs\n",
    "    if debug:\n",
    "        print(ids)\n",
    "        print(input_masks)\n",
    "        print(segment_ids)\n",
    "        print(input_label)\n",
    "        print(steps)\n",
    "        \n",
    "    #for i in trange(steps+1):\n",
    "    for i in range(1):\n",
    "        if i == steps:\n",
    "            temp_ids = ids[i * bs : len(ids)]\n",
    "            temp_segment_ids = segment_ids[i * bs: len(ids)]\n",
    "            temp_input_masks = input_masks[i * bs: len(ids)]\n",
    "        else:\n",
    "            temp_ids = ids[i * bs : i * bs + bs]\n",
    "            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n",
    "            temp_input_masks = input_masks[i * bs: i * bs + bs]\n",
    "        \n",
    "        temp_ids = temp_ids.to(device)\n",
    "        temp_segment_ids = temp_segment_ids.to(device)\n",
    "        temp_input_masks = temp_input_masks.to(device)\n",
    "        input_label = input_label.to(device)\n",
    "\n",
    "    return temp_ids, temp_segment_ids, temp_input_masks, input_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)\n",
    "\n",
    "\"\"\"\n",
    "input_sentence = train_0_data[0]  #negative\n",
    "temp_ids, temp_segment_ids, temp_input_masks, temp_input_label_ids = prep_example(input_sentence, 0)\n",
    "with torch.no_grad():\n",
    "    #a, b, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n",
    "    \n",
    "    eval_loss = model(temp_ids, temp_segment_ids, temp_input_masks, temp_input_label_ids)\n",
    "    print(\"Eval Loss\",type(eval_loss), len(eval_loss))\n",
    "    logits = model(temp_ids, temp_segment_ids, temp_input_masks)\n",
    "    print(\"Logits\", type(logits), len(logits),len(logits[0]), len(logits[1]), len(logits[2]))\n",
    "    \n",
    "    # there is some error ( i should probably have followed eval_bert more so?)   \n",
    "    \n",
    "    #HERE HERE HERE  #MAKE SURE YOU ARE USING THE RIGHT MODEL (( should it be model or model_cls ?))\n",
    "    \n",
    "    \n",
    "    #logits = logits.detach().cpu().numpy() \n",
    "    #label_ids = temp_input_label_ids.to('cpu').numpy()\n",
    "    #eval_accuracy = accuracy(logits, label_ids)\n",
    "    \n",
    "    #loss = eval_loss[0].mean().item()\n",
    "    #print(loss)   #-0.017504552379250526\n",
    "\n",
    "    #loss = eval_loss[1].mean().item()\n",
    "    #print(loss)   # -0.017707472667098045\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print(\"Temp IDs:\", temp_ids)  #[[  101,  2146,  1010, 11771,  1010,  1038,  8523,  8458,  6633,  3560, 1012,  2196,  2031,  1045,  2042,  2061,  5580,  2000,  2156,  4566, 6495,  4897,  1012,   102,     0,\n",
    "#print(\"Temp segments:\",temp_segment_ids)   #[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "#print(\"Temp input mask::\",temp_input_masks) #[[1, 1, 1, 1, 1, 1, \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = BertModel.from_pretrained(bert_classifier_model_dir)\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "#model.to(device)\n",
    "#model.eval()\n",
    "\n",
    "membeds = model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytorch_pretrained_bert.modeling.BertEmbeddings"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bertviz.bertviz.pytorch_pretrained_bert.modeling.BertEmbeddings'>\n",
      "['LayerNorm', 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dropout', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'position_embeddings', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'share_memory', 'state_dict', 'to', 'token_type_embeddings', 'train', 'training', 'type', 'word_embeddings', 'zero_grad']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#so both model loadings are the same, and both are slightly different than Captum Tutorial\n",
    "\n",
    "#model = BertModel.from_pretrained(bert_classifier_model_dir) \n",
    "print(type(model.embeddings))  #here its        <class 'bertviz.bertviz.pytorch_pretrained_bert.modeling.BertEmbeddings'>\n",
    "print([k for k in dir(model.embeddings) if not k.startswith('_')])\n",
    "\"\"\"\n",
    "['LayerNorm', \n",
    " 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dropout', 'dump_patches', 'eval', \n",
    " 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'modules', 'named_buffers', \n",
    " 'named_children', 'named_modules', 'named_parameters', 'parameters', 'position_embeddings', \n",
    " 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', \n",
    " 'requires_grad_', 'share_memory', 'state_dict', 'to', 'token_type_embeddings', \n",
    " 'train', 'training', 'type', 'word_embeddings', 'zero_grad']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n",
    "# this way model doesn't have model.embeddings, but it does have model.bert.embeddings\n",
    "#print(type(model.bert.embeddings))         #pytorch_pretrained_bert.modeling.BertEmbeddings\n",
    "#print([k for k in dir(model.bert.embeddings) if not k.startswith('_')])\n",
    "\"\"\"\n",
    "['LayerNorm', \n",
    " 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dropout', 'dump_patches', 'eval', \n",
    " 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'modules', 'named_buffers', \n",
    " 'named_children', 'named_modules', 'named_parameters', 'parameters', 'position_embeddings', \n",
    " 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', \n",
    " 'requires_grad_', 'share_memory', 'state_dict', 'to', 'token_type_embeddings', \n",
    " 'train', 'training', 'type', 'word_embeddings', 'zero_grad']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#whereas in tutorial model.embeddings is \n",
    "#print(\"Model Embedding\", type(model.embedding))  #torch.nn.modules.sparse.Embedding\n",
    "#print([k for k in dir(model.embedding) if not k.startswith('_')])\n",
    "\"\"\"\n",
    "['add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'embedding_dim', 'eval', \n",
    " 'extra_repr', 'float', 'forward', 'from_pretrained', 'half', 'load_state_dict', 'max_norm', 'modules', 'named_buffers', \n",
    " 'named_children', 'named_modules', 'named_parameters', 'norm_type', 'num_embeddings', 'padding_idx', 'parameters', \n",
    " 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', \n",
    " 'requires_grad_', 'reset_parameters', 'scale_grad_by_freq', 'share_memory', 'sparse', 'state_dict', 'to', 'train', \n",
    " 'training', 'type', 'weight', 'zero_grad']\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from tutorial\n",
    "#PAD_IND = TEXT.vocab.stoi['pad']\n",
    "#token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "#reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "#print(\"Refer Indices\",type(reference_indices), reference_indices)\n",
    "#<class 'torch.Tensor'> tensor([[6978, 6978, 6978, 6978, 6978, 6978, 6978]])\n",
    "\n",
    "#so i just need to make a tensor of the right size with PAD as the reference indice\n",
    "#torch.tensor(indexed, device=device)\n",
    "#pad_ids = tokenizer.convert_tokens_to_ids([\"[PAD]\"])  \n",
    "pad_ids = tokenizer.convert_tokens_to_ids([\"[SEP]\"])    #[102]\n",
    "print(pad_ids)  #[0]  .. [\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ['0', '0'] ['Long, boring, blasphemous. Never have I been so glad to see ending credits roll.']\n",
      "1\n",
      "Load LayerIntegratedGradient\n",
      "Eval:\n",
      "Eval Loss\n",
      "Eval Logits\n",
      "(1, 2) [[ 7.268938 -7.370504]]\n",
      "tensor([0], device='cuda:0') [0]\n",
      "1 tensor([0], device='cuda:0') [array([0])]\n",
      "<class 'torch.Tensor'>\n",
      "Now do attribution!\n",
      "torch.Size([1, 490])\n",
      "torch.Size([1, 490])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned:  {'eval_loss': 0.0, 'eval_accuracy': 1.0, 'steps': 1, 'examples': 1, 'preds': [array([0])], 'attributions_ig': tensor([[[-2.1389e-03, -7.1430e-03, -4.7225e-05,  ...,  8.9575e-04,\n",
      "           3.4303e-03,  4.5720e-04],\n",
      "         [ 9.4241e-05, -4.4118e-05,  6.4583e-04,  ..., -4.7069e-04,\n",
      "          -2.8796e-04, -1.9963e-04],\n",
      "         [ 1.0441e-04,  7.6457e-04,  4.4016e-04,  ..., -8.5060e-04,\n",
      "           2.0069e-04, -1.1677e-04],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00]]], device='cuda:0', grad_fn=<MulBackward0>)}\n",
      "Predicted [array([0])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TAKE 3 based on eval_bert.py\n",
    "from eval_bert import *\n",
    "# print(logging.getLoggerClass().root.handlers[0].baseFilename)\n",
    "# /home/diego/spr20_cf_gen/TDRG/logs/eval_bert.txt\n",
    "\n",
    "#from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerIntegratedGradients, visualization\n",
    "\n",
    "#lig = LayerIntegratedGradients(model, model.embeddings)       #BertModel.from_pretrained\n",
    "lig = LayerIntegratedGradients(model, model.bert.embeddings)    #BertForSequenceClassification ( this way runs out of memory !!)\n",
    "\n",
    "def pred_sentence(input_sentence, input_labels=[\"0\"]):\n",
    "    \n",
    "    processors = { \"yelp\": YelpProcessor, }\n",
    "    num_labels_task = { \"yelp\": 2, }\n",
    "    task_name = \"yelp\"\n",
    "    processor = processors[task_name]()\n",
    "    num_labels = num_labels_task[task_name]\n",
    "    label_list = processor.get_labels()\n",
    "\n",
    "    \"\"\" # Don't Reload Model cause it takes up too much GPU !!\n",
    "    \n",
    "    bc_model_dir = \"./data/lipton/sentiment/orig/bert_classifier_100epochs8b_490seqlen/\"  #Apr 24\n",
    "    output_config_file = os.path.join(bc_model_dir, \"bert_config.json\")\n",
    "    output_model_file = os.path.join(bc_model_dir, \"pytorch_model.bin\")\n",
    "\n",
    "    config = BertConfig(output_config_file)\n",
    "    model = BertForSequenceClassification(config, num_labels=num_labels)  #\n",
    "    model.load_state_dict(torch.load(output_model_file))\n",
    "\n",
    "    model.to(device)\n",
    "    \"\"\"\n",
    "\n",
    "    # change Diego\n",
    "    #eval_examples = processor.get_dev_examples(args.data_dir)\n",
    "    lines = []\n",
    "    for i in range(len(input_sentence)):\n",
    "        lines.append([input_sentence[i], input_labels[i]])\n",
    "\n",
    "    eval_examples = processor._create_examples(lines,set_type=\"dev\")\n",
    "    max_seq_len = 490\n",
    "    eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_len, tokenizer)\n",
    "    \n",
    "    eval_batch_size = 16   #maybe make this 1? \n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    \n",
    "    #reference_ids = torch.tensor(np.zeros(input_ids.shape, dtype=int))\n",
    "    print(len(lines))\n",
    "    reference_ids = torch.tensor(np.zeros((len(lines),490), dtype=int))\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    ret_preds = []\n",
    "    ret_attributions = [] \n",
    "    \n",
    "    # attribution score will be computed with respect to target class\n",
    "    # applying integrated gradients on the SoftmaxModel and input data point\n",
    "    \n",
    "    # ig = IntegratedGradients(model)\n",
    "    # \n",
    "    # https://captum.ai/tutorials/IMDB_TorchText_Interpret  \n",
    "    # <-- Do this after you finish ICML stuff   HERE\n",
    "    \n",
    "    \n",
    "    # then do similar thing you did but with attributes being removed at different thresholds ( make this a list ) \n",
    "    # compare this with attention results ( for both Yelp and Lipton for various thresholds )\n",
    "    # use auto metrics\n",
    "    #\n",
    "    # then move back to B-GST\n",
    "    #   make similar list of results (train/dev/test) for attention vs ig methods vs expected gradients\n",
    "\n",
    "    # ig = IntegratedGradients(model)\n",
    "\n",
    "    print(\"Load LayerIntegratedGradient\")\n",
    "    #lig = LayerIntegratedGradients(model, model.embeddings)       #BertModel.from_pretrained\n",
    "    #lig = LayerIntegratedGradients(model, model.bert.embeddings)    #BertForSequenceClassification ( this way runs out of memory !!)\n",
    "\n",
    "    # from constantly reloading model\n",
    "    #RuntimeError: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 11.91 GiB total capacity; 10.41 GiB already allocated; 838.25 MiB free; 10.48 GiB reserved in total by PyTorch)\n",
    "    attrbs = []\n",
    "    \n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        reference_ids = reference_ids.to(device)\n",
    "\n",
    "        print(\"Eval:\")#\",input_ids, segment_ids, input_mask, label_ids)\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            print(\"Eval Loss\")\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "            print(\"Eval Logits\")\n",
    "            \n",
    "        #print(type(logits),  type(logits[0]),   type(logits[1]),  type(logits[2]),len(logits)) \n",
    "        #    <class 'tuple'> <class 'list'> <class 'torch.Tensor'> <class 'list'>  3\n",
    "        #print(len(logits[0]),logits[1].shape, len(logits[2]))  #12 torch.Size([1, 768]) 12\n",
    "        #print(type(logits[0][0]))  #<class 'torch.Tensor'>\n",
    "        #print(dir(logits[1]))\n",
    "        #print(logits[1].cpu().numpy())\n",
    "        #print(np.argmax(logits[1], axis=1))\n",
    "        #print(logits[2])\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()     #BertSequenceForClassification:  \n",
    "        #logits = logits[1].cpu().numpy()          #FIX if using BertModel.from_pretrained(bert_classifier_model_dir)\n",
    "        \n",
    "        label_ids_np = label_ids.to('cpu').numpy()\n",
    "\n",
    "        print(logits.shape, logits)  #BertForSequenceClassification --> (1, 2)\n",
    "        #print(logits.shape) #BertModel.from_pretrained --> (1, 768)\n",
    "        print(label_ids, label_ids_np)    #[0]\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids_np)\n",
    "        ret_preds.append(np.argmax(logits, axis=1).flatten())\n",
    "        \n",
    "        print(tmp_eval_accuracy,label_ids,ret_preds)  # 0 [0] [array([77])]\n",
    "        \n",
    "        print(type(tmp_eval_loss))\n",
    "        eval_loss += tmp_eval_loss.mean().item()  #'tuple' object has no attribute 'mean'\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "\n",
    "        # maybe take Confidence scores as well ? \n",
    "        \n",
    "        #print(input_ids)  #tensor([[  101,  2146,  1010, 11771,  1038,  ..., 0, ], [  101,  2025,  2204, 999, ...,0] ])\n",
    "        #print(lines)      #[['Long, boring, blasphemous. ..', '0'], ['Not good! Rent ..', '0']]\n",
    "        #print(label_ids)  #[0 0]\n",
    "        #attributions, approx_error = ig.attribute(input, target=target_class_index, return_convergence_delta=True)\n",
    "        \n",
    "        \n",
    "        #attributions, approx_error = ig.attribute(input_ids, target=0, return_convergence_delta=True)\n",
    "        # RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; \n",
    "        #  but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\n",
    "        \n",
    "        #attributions, approx_error = ig.attribute(input_ids, target=label_ids, return_convergence_delta=True)\n",
    "        #RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; \n",
    "        #but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\n",
    "        #attributions, approx_error = ig.attribute((input_ids, segment_ids, input_mask), target=label_ids, return_convergence_delta=True)\n",
    "        \n",
    "        # https://captum.ai/tutorials/IMDB_TorchText_Interpret  \n",
    "        # if still not working, after class actually do the tutorial and look at what type/sizes inputs/refs are  ! HERE\n",
    "        #attributions_ig, delta = lig.attribute(input_ids, reference_indices, n_steps=500, return_convergence_delta=True)\n",
    "        \n",
    "        print(\"Now do attribution!\")\n",
    "        #attributions_ig, delta = lig.attribute(input_ids, n_steps=500, return_convergence_delta=True)  #out of memory\n",
    "        #attributions_ig, delta = lig.attribute(input_ids, reference_ids, n_steps=10, return_convergence_delta=True)\n",
    "        #AssertionError: Target not provided when necessary, cannot take gradient with respect to multiple outputs.\n",
    "        \n",
    "        print(input_ids.shape)  #torch.Size([1, 490])\n",
    "        #reference_ids = torch.tensor(np.zeros(max_seq_len))\n",
    "        #reference_ids = torch.tensor(np.zeros(input_ids.shape, dtype=int))\n",
    "        #reference_ids = reference_ids.to(device)\n",
    "        print(reference_ids.shape)#torch.Size([1, 490])\n",
    "        \n",
    "        #print(input_ids)  #tensor([[  101,  2146,  1010, 11771,  1010,  1038,  8523,\n",
    "        #print(reference_ids)  #tensor([[0., 0., 0., 0., 0.\n",
    "        \n",
    "        attributions_ig, delta = lig.attribute(inputs = input_ids, \n",
    "                                               baselines = reference_ids, \n",
    "                                               target = label_ids,\n",
    "                                               n_steps=10, \n",
    "                                               return_convergence_delta=True)\n",
    "        #RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)\n",
    "        #fixed scalar, now getting out of memory :(\n",
    "        #RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 11.91 GiB total capacity; 10.82 GiB already allocated; 10.25 MiB free; 11.29 GiB reserved in total by PyTorch)\n",
    "        # OR\n",
    "        #AssertionError: Target not provided when necessary, cannot take gradient with respect to multiple outputs.\n",
    "\n",
    "        # https://github.com/pytorch/captum/blob/5f0485e8bd63cbcdb9b7d814905618235117f7c0/captum/attr/_core/layer/layer_integrated_gradients.py#L25\n",
    "        \n",
    "        #from Tutorial\n",
    "        #attributions_ig, delta = lig.attribute(input_indices, reference_indices, n_steps=500, return_convergence_delta=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(\"Lines\",len(lines))\n",
    "        #print(\"InputIDs\",len(input_ids))\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    #loss = tr_loss/nb_tr_steps if args.do_train else None\n",
    "    result = {'eval_loss': round(eval_loss,5), 'eval_accuracy': round(eval_accuracy,5), 'steps': nb_eval_steps, \n",
    "              'examples': nb_eval_examples, 'preds': ret_preds, 'attributions_ig': attributions_ig}\n",
    "    return result\n",
    "    \n",
    "\n",
    "input_sentence = [train_0_data[i] for i in range(1)]\n",
    "input_label = [\"0\",\"0\"]\n",
    "print(\"Input: \",input_label,input_sentence)\n",
    "sen_pred = pred_sentence(input_sentence, input_label)\n",
    "print(\"Returned: \",sen_pred)\n",
    "#print(\"Predicted\", np.argmax(sen_pred[\"logits\"], axis=1))\n",
    "print(\"Predicted\", sen_pred['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attributions_ig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-55a8641df3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattributions_ig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'attributions_ig' is not defined"
     ]
    }
   ],
   "source": [
    "# NOW SHOW ATTRIBUTION PER IG\n",
    "# AND COMPARE WITH OTHER BRUTE FORCE TECHNIQUE\n",
    "\n",
    "#from tutorial\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    # attributions_ig, delta = lig.attribute(input_indices, reference_indices,  n_steps=500, return_convergence_delta=True)\n",
    "    # text is list of text tokens, \n",
    "    # pred is between 0 and 1 prob score, \n",
    "    # pred_ind is 0/1, \n",
    "    # label is pos/neg\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            Label.vocab.itos[pred_ind],\n",
    "                            Label.vocab.itos[label],\n",
    "                            Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text,\n",
    "                            delta))\n",
    "\n",
    "\n",
    "add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "\n",
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUATE TRAIN/DEV/TEST data accuracies for trained lipton data based BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  train0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 54/54 [00:32<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0  Returned:  1.0 851\n",
      "Evaluating  train1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 54/54 [00:35<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1  Returned:  1.0 856\n",
      "Evaluating  dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev0  Returned:  0.88525 122\n",
      "Evaluating  dev1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev1  Returned:  0.91057 123\n",
      "Evaluating  test0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:09<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test0  Returned:  0.90535 243\n",
      "Evaluating  test1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:10<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1  Returned:  0.8898 245\n",
      "Evaluating  ref0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref0  Returned:  0.88163 245\n",
      "Evaluating  ref1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:10<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref1  Returned:  0.86831 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NOW CHECK EVERYTHING HERE ( where do we err and where do we do well )\n",
    "\n",
    "lists = {\"train0\" : train_0_data, \"train1\": train_1_data, \"dev0\": dev_0_data, \"dev1\": dev_1_data, \"test0\": test_0_data, \"test1\": test_1_data, \"ref0\": ref_0_data, \"ref1\": ref_1_data}\n",
    "lists_preds = {}\n",
    "for k in list(lists.keys()):\n",
    "    print(\"Evaluating \",k)\n",
    "    cur = lists[k]\n",
    "    lab = \"0\" if \"0\" in k else \"1\"\n",
    "    num_ex = len(cur)\n",
    "    sub_train = [cur[i] for i in range(num_ex)]\n",
    "    sub_labels = [lab for i in range(num_ex)]\n",
    "    temp_preds = pred_sentence(sub_train, sub_labels)\n",
    "    lists_preds[k] = temp_preds\n",
    "    print(k,\" Returned: \",temp_preds['eval_accuracy'],temp_preds['examples'])      #{'eval_loss': 0.0, 'eval_accuracy': 1.0, 'steps': 54, 'examples': 856 .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW DO INTEGRATED GRADIENTS STUFF\n",
    "\n",
    "#https://captum.ai/docs/extension/integrated_gradients\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# attribution score will be computed with respect to target class\n",
    "target_class_index = 5\n",
    "\n",
    "# applying integrated gradients on the SoftmaxModel and input data point\n",
    "ig = IntegratedGradients(model)\n",
    "attributions, approx_error = ig.attribute(input, target=target_class_index, return_convergence_delta=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
