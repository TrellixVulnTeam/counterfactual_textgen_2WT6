#Looking at Lipton analysis notebook ( using thresh = 330 ) 

Original (train/dev/test)   <-- LIPTON ORIG .  mean 215 +- 90.6
max seq len: 490 468 455
mean : 215.811 221.388 216.373
median : 198.0 211.0 199.5
min seq len: 22 40 36
stddev : 90.676 92.466 87.528
num < thresh: 0.86 0.853 0.857

New (train/dev/test)   <-- CFs generated by humans for LIPTON .  mean 213.3 +- 89.8
max seq len: 486 438 465
mean : 213.484 218.971 214.088
median : 195.0 210.0 201.0
min seq len: 19 41 36
stddev : 89.857 90.588 86.247
num < thresh: 0.865 0.853 0.873

Yelp (train/dev/test)     <-- YELP review token lengths   .  mean 9.6 tokens +- 4.1
max seq len: 40 24 20
mean : 9.606 9.66 10.994
median : 9.0 10.0 11.0
min seq len: 1 1 6
stddev : 4.124 4.179 3.157
num < thresh: 1.0 1.0 1.0

Amazon (train/dev/test)   <-- Amazon review token lenghts.   mean 16 tokens +- 4.4
max seq len: 72 32 25
mean : 16.007 15.916 12.838
median : 16.0 15.5 13.0
min seq len: 8 9 9
stddev : 4.394 4.262 2.44
num < thresh: 1.0 1.0 1.0

Image Caption (train/dev/test)  <--- IMG caption lenghts.  mean 14.8 tokens +- 2.7
max seq len: 26 24 14
mean : 14.875 14.823 10.033
median : 15.0 15.0 10.0
min seq len: 4 7 6
stddev : 2.721 2.71 2.06
num < thresh: 1.0 1.0 1.0

ACL IMDB(train/dev/test)  <--- only 68% under 330 token size,  85 % under 490
max seq len: 3129 3097 3171
mean : 314.461 307.463 307.308
median : 233.0 230.0 230.0
min seq len: 11 9 8
stddev : 236.48 230.134 230.222
num < thresh: 0.684 0.698 0.696
num < thresh: 0.836 0.843 0.844


FOR LIPTON, it seems we are okay with using maxseqlen = 330  <-- this accounts for 85% of data without truncating at all
Though for other data sets, they are all contained by max len 70 (with the exception of amz which has 72 max <-- so mostly covered )..  In that case we'd need 490


#0.  move lipton data to data/ folder
    diego@microdeep:~/spr20_cf_gen/TDRG/data$ cp -R ../../lipton-data .
    
#0.1. pip install jupyterlab 
    jupyter lab --no-browser --port 6000
    ssh -p 52617 -NfL localhost:8898:localhost:6000 diego@microdeep.ece.utexas.edu .   ( on laptop )
    http://localhost:8898 ( on laptop ) 

# 1. start lipton stuff on normal code
        while its training look at what B-GST and G-GST produced in regards to human reference

    MAKE COPIES OF THINGS AND PUT THEM IN handle_lipton/
    #   Make BERT classifier for evaluation purposes ( a. prep data,     b. do GPU )
        a. python step1_bert_classification_training_data_preparation.py

        (tdrg) diego@microdeep:~/spr20_cf_gen/TDRG/handle_lipton$ ls ../data/lipton/sentiment/orig/bert_classifier_training/
        dev.csv  test.csv  train.csv
    
    #   b. GPU call ( in screen and using task_name=yelp)
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier/ --max_seq_length=330 --do_train --do_lower_case --train_batch_size=32 --num_train_epochs=3

        # RuntimeError: CUDA out of memory. Tried to allocate 124.00 MiB (GPU 0; 11.91 GiB total capacity; 11.13 GiB already allocated; 28.56 MiB free; 11.32 GiB reserved in total by PyTorch)

        # even if i could distribute this to 4 gpus that would still only give me 48 GB... what if i make batch sizes of 2?  WORKS
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_3epochs/ --max_seq_length=330 --do_train --do_lower_case --train_batch_size=2 --num_train_epochs=3 --do_eval

        #because i forgot "--do_eval"
        CUDA_VISIBLE_DEVICES=1 python eval_bert.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_3epochs/ --max_seq_length=330 --do_lower_case --train_batch_size=2 --num_train_epochs=3 --do_eval

        eval_accuracy = 0.4857142857142857
        eval_loss = 0.7747274916018209

        #seems batch size is too small.. try 24 instead of 32  ( gives error )
        RuntimeError: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 11.91 GiB total capacity; 11.19 GiB already allocated; 48.56 MiB free; 11.30 GiB reserved in total by PyTorch)

        #try 16.. Its running now... might need to run more epochs if still gives shitty accuracy... might also have to do with Yelp  Processor?
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_3epochs16b/ --max_seq_length=330 --do_train --do_lower_case --train_batch_size=16 --num_train_epochs=3 --do_eval

        04/23/2020 17:19:57 - INFO - __main__ -     eval_accuracy = 0.49795918367346936
        04/23/2020 17:19:57 - INFO - __main__ -     eval_loss = 0.693436413042007
        04/23/2020 17:19:57 - INFO - __main__ -     global_step = 321
        04/23/2020 17:19:57 - INFO - __main__ -     loss = 0.700539747131205

        #make it run 10epochs
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_10epochs16b/ --max_seq_length=330 --do_train --do_lower_case --train_batch_size=16 --num_train_epochs=10 --do_eval

        04/23/2020 17:34:11 - INFO - __main__ -   ***** Eval results *****
        04/23/2020 17:34:11 - INFO - __main__ -     eval_accuracy = 0.8979591836734694
        04/23/2020 17:34:11 - INFO - __main__ -     eval_loss = 0.6155484311522976
        04/23/2020 17:34:11 - INFO - __main__ -     global_step = 1070
        04/23/2020 17:34:11 - INFO - __main__ -     loss = 0.00021489930532820454

        #make it run 100epochs
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_100epochs16b/ --max_seq_length=330 --do_train --do_lower_case --train_batch_size=16 --num_train_epochs=100 --do_eval

        04/23/2020 20:05:24 - INFO - __main__ -     eval_accuracy = 0.9306122448979591
        04/23/2020 20:05:24 - INFO - __main__ -     eval_loss = 0.6695167317746147
        04/23/2020 20:05:24 - INFO - __main__ -     global_step = 10700
        04/23/2020 20:05:24 - INFO - __main__ -     loss = 2.5753561692347993e-06

        # TODO: maybe i should setup tensorboard to look at these results !  HERE
        #  xxx pip install jupyter-tensorboard
        #  xxx jupyter labextension install jupyterlab_tensorboard
        #    gives error : An error occured.
        #    ValueError: Please install nodejs >=10.0.0 before continuing. nodejs may be installed using conda or directly from the nodejs website.
        #    See the log file for details:  /tmp/jupyterlab-debug-sspd2x09.log

        # So instead of install new version of node.js system via npm 
        #just run tensorboard as usual, but via a port so that you can see it in a tab
        tensorboard --logdir=  --port 6001  (##make sure SummaryWriter is being used: jupyter lab --no-browser --port 6000 )
        ssh -p 52617 -NfL localhost:8896:localhost:6001 diego@microdeep.ece.utexas.edu . (laptop)
        
        jupyter lab --no-browser --port 6000

        # TODO: figure out how to run experiments in a distributed fashion!!  apex or whatever.. look at code

        #TRY SEQ LEN = 490 for 10epochs  ( ERROR with memory.. 92MB with 16 batchsize so do 8 batch size )
        CUDA_VISIBLE_DEVICES=1 python run_classifier.py --data_dir=./data/lipton/sentiment/orig/bert_classifier_training/ --bert_model=bert-base-uncased --task_name=yelp --output_dir=./data/lipton/sentiment/orig/bert_classifier_10epochs8b_490seqlen/ --max_seq_length=490 --do_train --do_lower_case --train_batch_size=8 --num_train_epochs=10 --do_eval

        04/24/2020 12:22:53 - INFO - __main__ -   ***** Eval results *****
        04/24/2020 12:22:53 - INFO - __main__ -     eval_accuracy = 0.9102040816326531
        04/24/2020 12:22:53 - INFO - __main__ -     eval_loss = 0.35673839559838655
        04/24/2020 12:22:53 - INFO - __main__ -     global_step = 2140
        04/24/2020 12:22:53 - INFO - __main__ -     loss = 0.017674224550191697

        # NOW DO FOR 100 EPOCHS
        04/24/2020 16:08:23 - INFO - __main__ -     eval_accuracy = 0.8979591836734694
        04/24/2020 16:08:23 - INFO - __main__ -     eval_loss = 0.9967757850885384    #this over fitt!!  what the fuck is the diff bet acc and loss
        04/24/2020 16:08:23 - INFO - __main__ -     global_step = 21400
        04/24/2020 16:08:23 - INFO - __main__ -     loss = 1.598462880214798e-06



    # DO HEAD SELECTION STUFF once training is done ( dataprep depends on it )
    #  See Head_selection.ipynb

    #  ISSUE: get_attention_for_batch(input_sentences, bs=32) is causing issues because of strings longer than 330 
    #   I either need to truncate those sentences or see if i can train bigger models ( ie, size 490 )  <-- try later first above batch size 8

    # Ok, that fixed it.. somewhat, for now use  /data/lipton/sentiment/orig/bert_classifier_10epochs8b_490seqlen/
        ## this one gave layer 9 and head 5 ( though all are fairly close <-- like how it is with other ones)


    # maybe add Expected Gradients to BERT CLASSIFIER TO GET ATTRIBUTION THAT WAY ( or other papers 2 in TO Read for NLP )
    # ( THIS WILL BE 2nd round )
    # https://github.com/suinleelab/attributionpriors 


    # installing jupyter lab extension: https://towardsdatascience.com/jupyterlab-2-0-edd4155ab897
        jupyter --version  #to verify you have 2.1
        pip install jupyter-lsp
        #must install nodejs before  ( which means I can now run tensorboardX through jupiter as well)
        conda install -c conda-forge nodejs
        jupyter labextension install @krassowski/jupyterlab-lsp
        pip install 'python-language-server[all]'
    

    #  Do DataPrep C and D while waiting on B
    #-- c. for B-GST, first had to run BERT_DATA_PREPARATION.ipynb 

        #see lipton_BERT_DATA_PREP
        # DONE BUT NO REF DATA  <--- IS THIS TRUE?  ACTUALLY WE DO HAVE LIPTONS REF DATA SO WHY NOT USE IT <-- DO THIS
        # FINISHED WITH REF DATA




    #-- d. for G-GST, have to run:
    # HERE NOW
    # 1. see lipton_Delete_Retrieve_Generate_Data_Preparation.ipynb   and then run 
        # DONE
        TDRG/data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/delete_retrieve_edit_model$ ls
        sentiment_dev_0_all_attrs.txt  sentiment_dev.txt               sentiment_test_all_attrs.txt     sentiment_train_1.txt
        sentiment_dev_0.txt            sentiment_test_0_all_attrs.txt  sentiment_test.txt               sentiment_train_all_attrs.txt
        sentiment_dev_1_all_attrs.txt  sentiment_test_0.txt            sentiment_train_0_all_attrs.txt  sentiment_train.txt
        sentiment_dev_1.txt            sentiment_test_1_all_attrs.txt  sentiment_train_0.txt
        sentiment_dev_all_attrs.txt    sentiment_test_1.txt            sentiment_train_1_all_attrs.txt

    # 2. lipton_tfidf_retrieve.ipynb
        # DONE
            
    # RUN E and F in Parallel for Training on GPU 2 and 3  while doing C and D
    #  e) openai_gpt_delete_and_generate.py for training Delete and Generate model. ( Blind GST )

        export DG_TRAIN_DATA=Path to the training file generated in the previous step
        export DG_EVAL_DATA=Path to the eval file generated in the previous step
        export DG_MODEL_OUT=Path to save the Delete and Generate model weights

        #python openai_gpt_delete_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset $DG_TRAIN_DATA --eval_dataset $DG_EVAL_DATA --train_batch_size 32 --eval_batch_size 32 --max_seq_length 85 --output_dir $DG_MODEL_OUT

        #NEED TO COMBINED _0 and _1 files  so that I have just TRAIN /  DEV / TEST

        CUDA_VISIBLE_DEVICES=2 python openai_gpt_delete_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_dev.txt --train_batch_size 16 --eval_batch_size 16 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/

            RuntimeError: CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 11.91 GiB total capacity; 11.11 GiB already allocated; 86.56 MiB free; 11.26 GiB reserved in total by PyTorch)   

        CUDA_VISIBLE_DEVICES=2 python openai_gpt_delete_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_dev.txt --train_batch_size 4 --eval_batch_size 4 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/

        
        # try with smaller batch size (8)  somehow 8 was even worse.   4 batch size works  #while this works do step D
Training loss: 3.66e-01 lr: -2.17e-07: 100%|███████████████████████████████████████████████████████████████████████| 289/289 [02:15<00:00,  2.13it/s]
Epoch: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [02:17<00:00, 137.51s/it]
Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:06<00:00,  6.18it/s]
        04/24/2020 18:26:51 - INFO - __main__ -   ***** Eval results *****
        04/24/2020 18:26:51 - INFO - __main__ -     eval_loss = 0.260596188215109  
        04/24/2020 18:26:51 - INFO - __main__ -     train_loss = 0.0
    
        #SO THIS DID BAD... is EVAL IS TOO SMALL?  <--- TRY EVALING ON EVAL + TEST MAYBE?  What about max_seq_length ? batch_size 

        # this also only ran 1 epoch --num_train_epochs ... try running 10 epochs 
        CUDA_VISIBLE_DEVICES=2 python openai_gpt_delete_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_dev.txt --train_batch_size 4 --eval_batch_size 4 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/bgst_10eps_4batch_490seq/  --num_train_epochs 10
Training loss: 2.93e-01 lr: 5.62e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:16<00:00,  2.12it/s]
Training loss: 2.42e-01 lr: 5.00e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 3.18e-01 lr: 4.37e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 2.27e-01 lr: 3.74e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.11it/s]
Training loss: 3.63e-01 lr: 3.12e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 2.47e-01 lr: 2.49e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 2.96e-01 lr: 1.86e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.09it/s]
Training loss: 2.48e-01 lr: 1.24e-05: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 2.74e-01 lr: 6.09e-06: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Training loss: 2.70e-01 lr: -1.73e-07: 100%|███████████████████████████████████████████████████████████████████████| 289/289 [02:17<00:00,  2.10it/s]
Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [23:11<00:00, 139.16s/it]
Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:06<00:00,  6.18it/s]
        04/25/2020 12:48:47 - INFO - __main__ -   ***** Eval results *****
        04/25/2020 12:48:47 - INFO - __main__ -     eval_loss = 0.22959108765308672
        04/25/2020 12:48:47 - INFO - __main__ -     train_loss = 0.0


        # running longer didn't help !!
        

    #  f) openai_gpt_delete_retrive_and_generate.py for training Delete, Retrieve and Generate model.  ( Guided GST )

        #same exports as above except:
        export DRG_MODEL_OUT=Path to save the Delete, Retrieve and Generate model weights

        #same call params
        CUDA_VISIBLE_DEVICES=3 python openai_gpt_delete_retrive_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_dev.txt --train_batch_size 8 --eval_batch_size 8 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/ggst_10eps_8b_490seq/ --num_train_epochs 10

        # 8 batch still to big.. so running with 4.
        04/25/2020 12:57:57 - INFO - __main__ -   ***** Eval results *****
        04/25/2020 12:57:57 - INFO - __main__ -     eval_loss = 0.22938464390925872
        04/25/2020 12:57:57 - INFO - __main__ -     train_loss = 0.0


        #ERROR.. I USED THE WRONG TRAINING/EVAL DATA
        CUDA_VISIBLE_DEVICES=3 python openai_gpt_delete_retrive_and_generate.py --model_name openai-gpt --do_train --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev.txt --train_batch_size 4 --eval_batch_size 4 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/ggst_10eps_4b_490seq/ --num_train_epochs 10

        #WAITING ON RETULTS
        04/26/2020 14:51:41 - INFO - __main__ -   ***** Eval results *****
        04/26/2020 14:51:41 - INFO - __main__ -     eval_loss = 0.2558836401440203    <--- only marginally better. 
        04/26/2020 14:51:41 - INFO - __main__ -     train_loss = 0.0


        # SO GENERAL methods for getting better results:
        # 1. trying doing eval with test data  ( there must be an error somehwere )
        # 2. try use 100 epoch BERT trainer which does slightly worse on Train, but way better on Eval data  <--- DO THIS NEXT !!!
            # print out attributes and what its getting right/wrong, use tensorboard!
        # 3. try using smaller max seq len
        
        #1. get rid of train and just do eval on test to see quickly 
        # for B-GST 
            # just to see evaluate all 10 saved models ( 1 per epoch )
            #output_model_file = os.path.join(args.output_dir, "pytorch_model_zero_grad_{}.bin".format(args.num_train_epochs))

            CUDA_VISIBLE_DEVICES=2 python openai_gpt_delete_and_generate.py --model_name openai-gpt --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/sentiment_test.txt --train_batch_size 4 --eval_batch_size 4 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/bgst_10eps_4batch_490seq/  --num_train_epochs 10

            # still gives shitty results
            Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:12<00:00,  6.60it/s]
            04/26/2020 14:41:10 - INFO - __main__ -   ***** Eval results *****
            04/26/2020 14:41:10 - INFO - __main__ -     eval_loss = 0.2297673033816474
            04/26/2020 14:41:10 - INFO - __main__ -     train_loss = None
            
        # for G-GST     
        CUDA_VISIBLE_DEVICES=3 python openai_gpt_delete_retrive_and_generate.py --model_name openai-gpt --do_eval --train_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train.txt --eval_dataset data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test.txt --train_batch_size 4 --eval_batch_size 4 --max_seq_length 490 --output_dir data/lipton/sentiment/orig/bert_classifier_training/processed_files_with_bert_with_best_head/ggst_10eps_4b_490seq/ --num_train_epochs 10

            Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:10<00:00,  6.57it/s]
            04/26/2020 16:37:30 - INFO - __main__ -   ***** Eval results *****
            04/26/2020 16:37:30 - INFO - __main__ -     eval_loss = 2.1047436735209297
            04/26/2020 16:37:30 - INFO - __main__ -     train_loss = None

            ## SOMETHING IS WRONG !!



    # g) Generate Predictions. 
    # see OpenAI_GPT_Pred_diego.ipynb for generating style transfer on the TEST DATA.



# 2. in parallel ( when things above are training ), see what yelp gets if we use IG or EG and maybe something instead of beam search ??

     SEE lipton_BERT_DATA_PREPERATION.ipynb  at bottom
     
     
May 9

Instead of training BERT based classifier just on lipton data, 
  instead run on ACL IMDB data and then fine tune on lipton?
    a. ACL IMDB data is now in data/aclImdb/

    b. cp handle_lipton/step1_bert_classification_training_data_preparation.py handle_lipton/step1_bert_classification_training_data_prep_for_acl_imdb.py

    c. ran script and now have correctly formatted data in data/aclImdb/bert_training_classifier/
    d. now run training via run_classifier ( make a version which trains on one, and then fine tunes on other)
        # because this loads bert and then trains on dataset


